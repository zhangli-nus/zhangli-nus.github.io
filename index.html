<!DOCTYPE html>
<!-- saved from url=(0023)https://zhangli-nus.github.io/ -->
<html lang="en-US"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="google-site-verification" content="-MIZfa2zxR5Mbb499LJJJ-aP5K4EcS6uxH5d6xlW2Mo" />

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Zhang Li's Home Page</title>
<meta name="generator" content="Jekyll v3.8.5">
<meta property="og:title" content="Zhang Li|张力">
<meta property="og:locale" content="en_sg">
<meta name="description" content="Welcome to Zhang Li’s Personal Homepage">
<meta property="og:description" content="Welcome to Zhang Li’s Personal Homepage">
<link rel="canonical" href="https://zhangli-nus.github.io/">
<meta property="og:url" content="https://zhangli-nus.github.io/">
<meta property="og:site_name" content="zhangli-nus.github.io">
<meta property="Keywords" content="ZhangLi,LiZhang,张力,NUS,ALIBABA">
<script type="application/ld+json">
{"@type":"WebSite","url":"https://zhangli-nus.github.io/","headline":"Zhang Li (张力)","name":"zhangli-nus.github.io","description":"Welcome to Zhang Li’s Personal Homepage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#157878">
<link rel="stylesheet" href="./zhangli_nus.github.io_files/style.css">
<style type="text/css">
ul li {
    display: inline;
    margin: 0;
    margin-right: 0px;
    padding: 0;
}
</style>
</head>



<body>

<section class="page-header">
<h1 class="project-tagline">Welcome to Zhang Li's Personal Homepage</h2>
</section>

<section class="main-content">

<div style="width:auto;margin-left:auto;margin-right:auto">
<table width="100%" border="0">
 <tr>
<td width="50%">
<br/>
<span lang="zh-cn">
            <font size="5" face="georgia"><b>Zhang Li (</b></font><font size="5" face="华文行楷">张力</font><b><font size="5" face="georgia">)</b></font></span>
</div>
<div id="header">
<div id="profile">
<font size="3" face="georgia">
<p>
Senior Research Engineer and Team Lead<br>
<i><a href="http://www.alibaba-inc.com" target="_blank">Alibaba Group.</a><br/>
No. 969, Wen Yi West Road, HangZhou, Zhe Jiang Province, China<br/>
</i>
Email: lizhang.nus2010[AT]gmail.com<br/>
</p>
</td>
<td width="50%"><img src="zhangli_nus.github.io_files/img/personal1.jpg" width="300px"/>
</td>
</tr>
</table>
</div>
</div><!--end of header-->


<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="research interest"> <font size="5" face="georgia">Short Bio</font></h2>
<p> <font size="3" face="georgia">
I obtained my Ph.D degree, major in machine learning and computer vision, from School of Computing, National University of Singapore (NUS), where I was supervised by by<a href="https://tsim49.wixsite.com/terencesim"> Prof Terence Sim</a>. Before joining Alibaba, I was leading a research group in Mozat for two years, a local internet firm in Singapore. Up to date, I was granted five patents with over ten publications shown in <a href="https://scholar.google.com/citations?user=0yMyTyQAAAAJ&hl=en">my google profile</a>. I'm severing as the local organizer in Alibaba for  <a href="http://www.ccks2019.cn/en/?page_id=24">CCKS</a> and an adjunct supervisor in ShenZhen university. I am co-editing a book in Chinese, "Knowledge Graph: from theory to pratice". 
<br>
My research aims at exploiting deep learning on multi-modality data including text, image and video for face recognition, fashion analysis and geographic service to build domain-specific knowledge graph. 

</font></p></div>



<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="education"> <font size="5" face="georgia">Education</font></h2>
<p> <font size="3" face="georgia">
&bull;Aug 2010~May 2015 - Ph.D, Computer Science, National University of Singapore, supervised by<a href="https://tsim49.wixsite.com/terencesim"> Prof Terence Sim. </a>
<br>
&bull;Sep 2006~July 2010 - Bachelor, Computer Science, HuaZhong University Science & Technology with <strong>first rank honor</strong>. 

</font></p></div>

<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="working-experience"><font size="5" face="georgia">Working Experience</font></h2>
<p> <font size="3" face="georgia">
&bull;Nov 2017~now - Senior Algorithm Engineer & Team Lead, Alibaba Group. I'm leading a team to use computer vision and language processing to provide geographic based data service on middle platform to multiple partners, such as Fliggy, Eleme, Koubei, Taobao and Tmall. 
<br>
&bull;June 2015-Nov 2017 - Head of R&D, Mozat Pte Ltd. I set up the team and lead the team to develop in-depth image and text understanding techniques to understand fashion. Our product, <a href="http://www.mozat.com/about#tab2">Stylepedia</a>, was once <strong>ranked 1st</strong> in Google Play and App Store under lifestyle track.
</font></p></div>

<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="awards"><font size="5" face="georgia">Awards</font></h2>
<p> <font size="3" face="georgia">
&bull;<font color=red>Excellent Staff in Alibaba</font>(10/~1000) during 2018~2019. <a href="zhangli_nus.github.io_files/img/reward.jpg">See photos</a>.
  <br>
&bull;Excellent Performance in Mozat during 2016 & 2017
  <br>
&bull;<font color=red>Best Student Paper Honorable Mention Award</font> in Face and Gesture 2013
  <br>
&bull;The Second Rank Award in Action Recognition Competition in ICPR 2012
<!--   <li>Premia Student Traval Grant Award in ICPR2012</li>
  <li>Research Scholarship in 2010~2014</li> -->
  <br>
&bull;Meritorious Winner in MCM Contest in 2009
  <br>
&bull;National Scholarship in 2007~2009
</font></p></div>

<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="projects"><font size="5" face="georgia">Projects</font></h2>
<p> <font size="3" face="georgia">
  <ol>
    <li><STRONG>Automatic Data Integration System To Generate Point of Interest in Billion-level</STRONG>. May 2018~now in Alibaba<br>
    We built a system on cloud platform, Dataworks, to generate standard point of interest in billion-level. This system can solve many problems: a) correct exsiting data b) enrich attributes of exiting data c) provide new data. This project has improved data quality in Fliggy (from 3M to 10M, accuracy from 58% to 98%), merchant settle-in efficency in Tmall (200+% improvement) and gained over 100 million direct GMV through hotel reservation. We also use this system to serve for Koubei, Alipay and Eleme.<br>
    My role in this project to design the architure of this big data processing pipeline and develop critical algorithm components. Two papers are written and two patents are granted in this project.<br>
    Algorithm: Word Embedding (Skip-Gram, CBow, Glove, FastText, Elmo), Sentence Embedding, Text Classification, Image Athestic Model
    </li>
    <li><STRONG>Smart Address Filling Assistant</STRONG>. Sep 2019~now in Alibaba<br>
    Existing address filling in Taobao is purely through text, while this is time-consuming for customers. Moreover, in local life business, they require very accurate location to optimize their logistic distribution. Since the text from the customers is unconstrained, the noise is usually very heavy. We built an intelligent system that can help user filling address via simple text pasting and smart poi list recommendatation. We serve for Taobao, Tmall, Taoxianda and Maochao. Our address average parsing accuracy is 96% and poi ctr can improve 2%. We have accumulated 1.4 milllion building with over 99% accuracy. One paper is under writing and one patent is granted<br>
    My role in this project is to develop algorithm components, such as address parsing and address matching.<br>
    Technique: Sequence Labeling(HMM, CRF, BiLSTM-CRF etc), Pretrain Language Model
    </li>
    <li><STRONG>ConceptNet Matching With Text Sellpoint Summary and Image Understanding for Short Video Generation</STRONG>. Oct 2019~now in Alibaba<br>
    We provide a framework to generate short video for point of interest through merchant raw input and user comments. The main challenge is unconstrained text and unconstrained image from merchant, while customer only focus on certain part of the sellpoints. We develop image-text matching model that can extract high-quality text and athestic image to serve hotel merchant through text generation and cross modality matching with ConceptNet. This system has been integrated into hotel release system. The overall accept rate for the synthesized video is 70%. See <a href=zhangli_nus.github.io_files/video/hotel.mp4>demos</a> here. A patent is granted. <br>
    Technique: Image Athestic Evaluation, ConceptNet for Image-Text Matching, Text Genaration
    </li>
    <li><STRONG>Fashion Analysis from Web-crawled Photos and Try-on Effect Synthesis</STRONG>. June 2016~Oct 2017 in Mozat<br>
    We propose to Download Stylepedia app and see details, or visit <a href="http://www.mozat.com/fashion">here.</a>Internet. <br>
    We develop fashion parsing service with Django with Nginx framework. The service packages includes hash-tag recognition (OCR), fashion garment detection(SOLO, FasterRCCN, YOLO etc) and image classification (GoogleNet, Residual Network, VGG etc) and keypoint based try-on synthesis. The mAP can be up to 0.60 for typical fashion garments and the classification accuracy can be 0.95%. 
    Technique: Image Detection, Image Classification, Moving Least Square Warpping
    </li>
    <li><STRONG>Special Face Effect Synthesis</STRONG>. June 2015~July 2016 in Mozat<br>
    We developed different image editing and face analysis tools for the users. For <a href=zhangli_nus.github.io_files/project/moment.jpg>realistic effect</a>, we develop face detection and possion image editing algorithm to perform the synthesis. The overall user accept rate is 95%. For <a href=zhangli_nus.github.io_files/project/mango.jpg>mango style</a>, we use landmark detection to exaggerate the most significant face features. For <a href="makeup.html">face makeup</a>, we develop a layer seperation and image warpping technique to get quite satisfying results (over 86% accept rate). These techniques were applied on Shabik, a leading chatting app in Middle East.<br>
    </li>
  </ol>

</font></p></div>

<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="projects"><font size="5" face="georgia">Publications</font></h2>
<table width="780" border="0" cellspacing="0" cellpadding="0">
  <!-- paper one -->
  <tr>
  <a href="https://scholar.google.com/citations?user=0yMyTyQAAAAJ&hl=en">
  <font size="3" face="georgia"><u><strong>SentPWNet: A Unified Sentence Pair Weighting Network for Task-specific Sentence Embedding</u></strong></font>
  </a>
  </tr>
  <br>
  <tr>
  <font size="3" face="georgia"><u><strong>Li Zhang</u></strong>, Han Wang, Lingxiao Li, Wei Zhang, Huajun Chen</font>
  </tr>
  <tr>
  <table width="780" border="0" cellspacing="0" cellpadding="0">
  <td width="300"><img src="zhangli_nus.github.io_files/project/sentpwnet.jpg" width="300" border=1 /></td>
  <td width="480" height="200" valign="top"><p align="justify" class="myintro"><font size="3" face="georgia">Pair-based metric learning has been widely adopted to learn sentence embedding in many NLP tasks. However, it is known that the sentence representation can be biased when the sampled sentence pairs deviate from the true distribution of all sentence pairs. In this paper, instead of one time pair selection and learning on equal weighted pairs, we propose a unified locality weighting and learning framework. Extensive experiments on four public available datasets and a self-collected place search benchmark with 1.4 million places clearly demonstrate that our model consistently outperforms existing sentence embedding methods with comparable efficiency. Submitted in SIGKDD2020.</font></p></td>
  </table>
  </tr>
  <br>

  <!-- paper two -->
  <tr>
  <a href="https://scholar.google.com/citations?user=0yMyTyQAAAAJ&hl=en">
  <font size="3" face="georgia"><u><strong>Multi-Relational Loss: A Relational Loss For Text and Image Embedding</u></strong></font>
  </a>
  </tr>
  <br>
  <tr>
  <font size="3" face="georgia"><u><strong>Li Zhang</u></strong>, Lingxiao Li, Han Wang</font>
  </tr>
  <tr>
  <table width="780" border="0" cellspacing="0" cellpadding="0">
  <td width="300"><img src="zhangli_nus.github.io_files/project/multirelational.jpg" width="300" border=1 /></td>
  <td width="480" height="200" valign="top"><p align="justify" class="myintro"><font size="3" face="georgia">A family of pair based loss has been proposed to learn image embeddings. Recent works focus on utilizing similarity loss among same labels towards anchor points to weights the pairs, which would throw away many useful informational throught different pairs. In this paper, we propose a new multi-relational loss, which computes the weights based on all its locality neighborings including positive and negative neighbors. Extensive experiments on three public available datasets demontrates that our model can gain the state-of-the-art performence of metric leanring in both image retrieval and text retrieval tasks. </font></p></td>
  </table>
  </tr>  
  <br>

  <!-- paper three -->
  <tr>
  <a href="https://ieeexplore.ieee.org/document/8737513">
  <font size="3" face="georgia"><u><strong>Brush like a Dentist: Accurate Monitoring of
Toothbrushing via Wrist-Worn Gesture Sensing</u></strong></font>
  </a>
  </tr>
  <br>
  <tr>
  <font size="3" face="georgia">Chengwen Luo etc, <u><strong>Li Zhang</u></strong>, Albert Y. Zomaya</font>
  </tr>
  <tr>
  <table width="780" border="0" cellspacing="0" cellpadding="0">
  <td width="300"><img src="zhangli_nus.github.io_files/project/dentist.jpg" width="300" border=1 /></td>
  <td width="480" height="200" valign="top"><p align="justify" class="myintro"><font size="3" face="georgia">Oral health has significant impact on people's over-all well-being. In this work, we propose Hygiea, an energy-efficient and highly-accurate toothbrushing monitoring system which exploits IMU-based wrist-worn gesture sensing using unmodified toothbrushes. Hygiea incorporates a number of novel signal preprocessing techniques to automatically transform the sensory input during arbitrary toothbrushing activities to the consistent user coordinate system. To distinguish different brushing actions, Hygiea leverages an emerging deep learning model to achieve fine-grained activity recognitions. Moreover, a POMDP model is incorporated for sampling control to balance activity detection and energy efficiency. Extensive real-world experiments show that the Hygiea system achieves a 11.7% accuracy gain compared to the state-of-the-art while maintaining energy-efficiency and zero modification on the toothbrushes. Published in <font color=red>INFORCOM2019</font>.</font></p></td>
  </table>
  </tr>  
  <br>

  <!-- paper four -->
  <tr>
  <a href="https://scholar.google.com/citations?user=0yMyTyQAAAAJ&hl=en">
  <font size="3" face="georgia"><u><strong>Controllable Face Privacy</u></strong></font>
  </a>
  </tr>
  <br>
  <tr>
  <font size="3" face="georgia"><u><strong>Li Zhang</u></strong>, Terence Sim</font>
  </tr>
  <tr>
  <table width="780" border="0" cellspacing="0" cellpadding="0">
  <td width="300"><img src="zhangli_nus.github.io_files/project/privacy.jpg" width="300" border=1 /></td>
  <td width="480" height="200" valign="top"><p align="justify" class="myintro"><font size="3" face="georgia">We present the novel concept of Controllable Face Privacy. Existing methods that alter face images to conceal identity inadvertently also destroy other facial attributes such as gender, race or age. This all-or-nothing approach is too harsh. Instead, we propose a flexible method that can independently control the amount of identity alteration while keeping unchanged other facial attributes. To achieve this flexibility, we apply a subspace decomposition onto our face encoding scheme, effectively decoupling facial attributes such as gender, race, age, and identity into mutually orthogonal subspaces, which in turn enables independent control of these attributes. Our method is thus useful for nuanced face de-identification, in which only facial identity is altered, but others, such gender, race and age, are retained. Published in FG2015(ORAL).</font></p></td>
  </table>
  </tr>  
  <br>

  <!-- paper five -->
  <tr>
  <a href="https://scholar.google.com/citations?user=0yMyTyQAAAAJ&hl=en">
  <font size="3" face="georgia"><u><strong>New Hope to Recognize Identical Twins: Expression, Ear, Talking and Voice</u></strong></font>
  </a>
  </tr>
  <br>
  <tr>
  <font size="3" face="georgia"><u><strong>Li Zhang</u></strong>, Jing Li, Dong Guo, Terence Sim</font>
  </tr>
  <tr>
  <table width="780" border="0" cellspacing="0" cellpadding="0">
  <td width="300"><img src="zhangli_nus.github.io_files/project/twins.jpg" width="300" border=1 /></td>
  <td width="480" height="200" valign="top"><p align="justify" class="myintro"><font size="3" face="georgia">Identical twins pose an interesting challenge for recognition systems due to their similar appearance. Although various biometrics have been proposed for the problem, existing works are quite limited due to the difficulty of obtaining a twins database. To encourage the methods for twins recognition and make a fair comparison of them by using the same database, we collected an audio-visual twins database at the Sixth Mojiang International Twins Festival held on 1 May 2010,China. Our database contains 39 pairs of twins in total, including Chinese, American and Russian subjects. This database contains several face images, facial motion videos and audio records for each subject. To address twin recogntion, we propose to use <a href="expression.html">face motion</a>, talking pattern, voice, ear and face recognition. <font color=red>Eight</font> papers are published and we won <font color=red>Best Hornorable Mention in FG2013</font>. </font></p></td>
  </table>
  </tr>  
  <br>

  <!-- paper five -->
  <tr>
  <a href="https://scholar.google.com/citations?user=0yMyTyQAAAAJ&hl=en">
  <font size="3" face="georgia"><u><strong>Toward Large-population Face Identification in Unconstrained Videos</u></strong></font>
  </a>
  </tr>
  <br>
  <tr>
  <font size="3" face="georgia">Luoqi Liu, <u><strong>Li Zhang</u></strong>, Hairong Liu, Shuicheng Yan</font>
  </tr>
  <tr>
  <table width="780" border="0" cellspacing="0" cellpadding="0">
  <td width="300"><img src="zhangli_nus.github.io_files/project/largescaleface.jpg" width="300" border=1 /></td>
  <td width="480" height="200" valign="top"><p align="justify" class="myintro"><font size="3" face="georgia">We investigate large-scale face identification in unconstrained videos with 1000 subjects. This problem is very challenging, and until now most studies have only considered the scenarios with a small number of subjects and videos captured in controlled laboratory environments. First, we set up a large-scale video database in an unconstrained environment, Celebrity-1000, with data collected from video-sharing websites. Second, we boost the efficiency of multitask joint sparse representation (MTJSR) algorithm for video-based face identification on Celebrity-1000. Extensive experiments show several orders-of-magnitude speedup with this new optimization method, and also demonstrate the superiorities of the accelerated MTJSR algorithm over several popular baseline algorithms. Published in IEEE Transactions on Circuits and Systems for Video Technology 2014</font>. </font></p></td>
  </table>
  </tr>  
  <br>

</table>



<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="books"><font size="5" face="georgia">Books</font></h2>
<font size="3" face="georgia">
&bull; <strong>Knowledge Graph: From Thoery to Practice. </strong>Mechanical Press. To Be Appeared. 
<!-- &bull;CN Patent/Innovation: 基于图文匹配的智能实体速览系统 <strong>内部编号: 101247162</strong>, 2019<br>
&bull;CN Patent/Innovation: 强化学习在数据一致性预测的应用 <strong>内部编号: 101052124</strong>, 2019<br>
&bull;CN Patent/Innovation: 一套poi知识自动生产方案 <strong>内部编号: 100617702</strong>, 2019<br>
&bull;CN Patent/Innovation: 基于知识图谱的推理计算方案 <strong>内部编号: 100830983</strong>, 2019<br>
&bull;CN Patent/Innovation: 基于路径优化的智能行程方案 <strong>内部编号: 100830652</strong>, 2019<br> -->
</font></p></div>

<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="awards"><font size="5" face="georgia">Patents</font></h2>
<font size="3" face="georgia">
&bull;A Short Video Clips Based Visual Storytelling System Through Entity Summary. CN Patent No: 101247162<br>
&bull;Hotel Availability Prediction System Via Reinforcement Learning. CN Innovation No: 101052124<br>
&bull;An Automatic Point of Interest Production System Through Entity Alignment. CN Innovation No: 100617702<br>
&bull;A Knowledge Graph Based Inference Framework. CN Innovation No: 100830983<br>
&bull;A Trip Planner Through Point Network. CN Innovation No: 100830652<br>
<!-- &bull;CN Patent/Innovation: 基于图文匹配的智能实体速览系统 <strong>内部编号: 101247162</strong>, 2019<br>
&bull;CN Patent/Innovation: 强化学习在数据一致性预测的应用 <strong>内部编号: 101052124</strong>, 2019<br>
&bull;CN Patent/Innovation: 一套poi知识自动生产方案 <strong>内部编号: 100617702</strong>, 2019<br>
&bull;CN Patent/Innovation: 基于知识图谱的推理计算方案 <strong>内部编号: 100830983</strong>, 2019<br>
&bull;CN Patent/Innovation: 基于路径优化的智能行程方案 <strong>内部编号: 100830652</strong>, 2019<br> -->
</font></p></div>


<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="awards"><font size="5" face="georgia">Activity</font></h2>
<font size="3" face="georgia">
&bull;Member of local organizer of <a href="zhangli_nus.github.io_files/img/personal3.jpg">CCKS</a> and <a href="zhangli_nus.github.io_files/img/personal4.jpg">Yunxi Conference</a> in 2019<br>
&bull;Invited talk at NanJing University, by Prof. Zheng in Oct 2018.<br>
&bull;Invited talk at ShenZhen University and be an adjunct master advisor, by Prof. Luo in Dec 2017<br>
&bull;Invited talk at Premia AGM, Singapore in 2013<br>
&bull;Student member of Pattern Recognition and Machine Intelligence Association (PREMIA) in 2012<br>
&bull;Teaching Assistant of Computer Vision and Pattern Recognition in 2013<br>
&bull;Teaching Assistant of Uncertainty Modeling in AI in 2012
</font></p></div>


<div id="about" style="width:auto;margin-left:auto;margin-right:auto">
<h2 id="awards"><font size="5" face="georgia">Expertise</font></h2>
<font size="3" face="georgia">
&bull;Deep Learning Framework of Caffe in depth, Pytorch<br>
&bull;Python and C/C++<br>
&bull;Git, Basic Shell, Django, Latex<br>
</font></p></div>


<footer class="site-footer">
<span class="site-footer-credits">All rights reserved@Zhang Li.</span>
</footer>
    </section>
</body>
</html>